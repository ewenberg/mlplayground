{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pydatagen.functions import textify\n",
    "from fastai.vision.all import *\n",
    "\n",
    "raw = pd.read_csv(\"../datagen/small_phone_number_sample.csv\")\n",
    "raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lots of data here.  The phone column contains positive examples, the rest essentially are negative examples.  However, we essentially need to turn each individual column into a set of key,value pairs (and label each row appropriately) before we can feed the data to a classifier.\n",
    "\n",
    "First we'll create a label column, initialized with all 0's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw['is_phone'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use the 'melt' function to make each column a different key, and let the 'is_phone' column be the value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# melted = raw.melt(id_vars=['is_phone'], value_vars=['locale','name','language','phone','license','address','city','country'])\n",
    "melted = raw.melt(id_vars=['is_phone'], value_vars=['locale','name','language','phone','license','address','city','country'])\n",
    "melted.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously a lot of duplicates for locale here (which is more of a categorical variable), so we might as well remove those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melted = melted.drop_duplicates()\n",
    "melted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_counts = melted.groupby(['variable']).size()\n",
    "\n",
    "x_pos = [i for i, _ in enumerate(group_counts)]\n",
    "\n",
    "plt.figure(figsize=(9, 5))\n",
    "plt.bar(x_pos, group_counts.values)\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xlabel(\"Type\")\n",
    "plt.xticks(x_pos, group_counts.index)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have roughly the same number of records for phone (positive examples), as we do for name, license, and address (negative examples).  We'll\n",
    "create a 50-50 mix of positive to negative examples and draw a stratified sample for the negatives from each of name, license, and address."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set 'is_phone' column on the phone values\n",
    "melted.loc[melted['variable'] == 'phone', 'is_phone'] = 1\n",
    "\n",
    "positives = melted.loc[melted['is_phone'] == 1]\n",
    "positives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create the negative examples of roughly the same size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negatives = melted.loc[melted.variable.isin(['name', 'address', 'license'])].sample(frac=0.33, replace=False, random_state=42)\n",
    "negatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check our negatives count just to be sure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_counts = negatives.groupby(['variable']).size()\n",
    "\n",
    "x_pos = [i for i, _ in enumerate(neg_counts)]\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.bar(x_pos, neg_counts.values)\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xlabel(\"Type\")\n",
    "plt.xticks(x_pos, neg_counts.index)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(positives), len(negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data_df = pd.concat([positives, negatives])\n",
    "textified_df = pd.DataFrame({'textified': full_data_df['value'].astype(str).apply(lambda x: textify(x, length=30))})\n",
    "textified_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(textified_df['textified'].to_list())\n",
    "# .loc[:,:29].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not sure why but our 30 element textified list is somehow being split into 69 columns.  Need to select out only the columns we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df = pd.DataFrame(textified_df['textified'].to_list()).loc[:,:29]\n",
    "feature_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df = full_data_df['is_phone']\n",
    "label_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# train_x_df = feature_df.sample(frac=0.9, replace=False, random_state=42)\n",
    "\n",
    "train_x_df, valid_x_df, train_y_df, valid_y_df = train_test_split(feature_df, label_df, test_size=0.10, random_state=42)\n",
    "train_x_df.shape, valid_x_df.shape, train_y_df.shape, valid_y_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_tens = torch.tensor(train_x_df.values)\n",
    "train_y_tens = torch.tensor(train_y_df.values).unsqueeze(1)\n",
    "valid_x_tens = torch.tensor(valid_x_df.values)\n",
    "valid_y_tens = torch.tensor(valid_y_df.values).unsqueeze(1)\n",
    "\n",
    "train_x_tens.shape, train_y_tens.shape, valid_x_tens.shape, valid_y_tens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = list(zip(train_x_tens.float(), train_y_tens))\n",
    "validset = list(zip(valid_x_tens.float(), valid_y_tens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size of about 100 seems best so far\n",
    "traindl = DataLoader(trainset, batch_size=256)\n",
    "# xb,yb = first(traindl)\n",
    "# print(\"Training example: {}, {}\".format(xb,yb))\n",
    "\n",
    "# validdl = DataLoader(validset, batch_size=30)\n",
    "validdl = DataLoader(validset, batch_size=256)\n",
    "# xt, yt = first(validdl)\n",
    "# print(\"Validation example: {}, {}\".format(xt.shape, yt.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phone_loss(predictions, targets):\n",
    "    predictions = predictions.sigmoid()\n",
    "    return torch.where(targets == 1, 1-predictions, predictions).mean()\n",
    "\n",
    "def phone_accuracy(xb, yb):\n",
    "    preds = xb.sigmoid()\n",
    "    correct = (preds > 0.5) == yb\n",
    "    return correct.float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = DataLoaders(traindl, validdl)\n",
    "\n",
    "simple_net = nn.Sequential(\n",
    "    nn.Linear(30, 20),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(20, 10),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(10, 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(dls, simple_net, opt_func=SGD, loss_func=phone_loss, metrics=phone_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(80, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try with resnet\n",
    "learn = cnn_learner(dls, resnet18, pretrained=False,\n",
    "                    loss_func=F.cross_entropy, metrics=phone_accuracy)\n",
    "learn.fit_one_cycle(1, 0.1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
